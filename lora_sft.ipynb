{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# const\n",
    "DATASET = 'Flmc/DISC-Med-SFT'\n",
    "BASE_MODEL = 'Qwen/Qwen2.5-0.5B'\n",
    "SFT_MODEL = 'qwen2.5-0.5b-disc-med-sft'\n",
    "MAX_TENSOR_DIM = 68\n",
    "MAX_SIZE = 1000\n",
    "MAX_BATCH_SIZE = 128\n",
    "MIN_BATCH_SIZE = 16\n",
    "GRADIENT_ACCUMULATION_STEPS = 16\n",
    "LEARNING_RATE = 2e-3\n",
    "TRAIN_EPOCHS = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T03:18:05.682627Z",
     "start_time": "2024-10-10T03:18:05.678391Z"
    }
   },
   "id": "bf71207124f2304f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T03:18:12.232902Z",
     "start_time": "2024-10-10T03:18:05.692154Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "disc_med_sft = load_dataset(DATASET, cache_dir='./cache')['train']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f38ccb4a75d448aa4faa6e0f764cd23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T03:18:12.250128Z",
     "start_time": "2024-10-10T03:18:12.242105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# peek\n",
    "disc_med_sft"
   ],
   "id": "ca6aba3069d0cc75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'source', 'conversation'],\n",
       "    num_rows: 464898\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T03:18:39.543062Z",
     "start_time": "2024-10-10T03:18:12.283314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inputs = list[str]()\n",
    "labels = list[str]()\n",
    "conversation_pair = list[tuple]()\n",
    "conversations_trunks = disc_med_sft['conversation']\n",
    "conversations_trunk = list[dict]()\n",
    "for conversation_trunk in conversations_trunks:\n",
    "    for a_conversation in conversation_trunk:\n",
    "        conversations_trunk.append(a_conversation)\n",
    "conversations = list[dict]()\n",
    "for index, conversation in enumerate(conversations_trunk):\n",
    "    if (\n",
    "            index + 1 < len(conversations_trunk)\n",
    "            and conversation['role'] == 'user' \n",
    "            and conversations_trunk[index + 1]['role'] == 'assistant'\n",
    "    ):\n",
    "        conversations.append((conversation, conversations_trunk[index + 1]))\n",
    "for conversation in conversations[:MAX_SIZE]:\n",
    "    inputs.append(conversation[0]['content'])\n",
    "    labels.append(conversation[1]['content'])\n",
    "print(f'{len(inputs)} inputs, {len(labels)} labels')\n",
    "train_inputs, eval_inputs, train_labels, eval_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(f'{len(train_inputs)} train inputs, {len(train_labels)} train labels')\n",
    "print(f'{len(eval_inputs)} eval inputs, {len(eval_labels)} eval labels')\n",
    "{\n",
    "    'train inputs': train_inputs[:10],\n",
    "    'train labels': train_labels[:10],\n",
    "    'eval inputs': eval_inputs[:10],\n",
    "    'eval labels': eval_labels[:10]\n",
    "}"
   ],
   "id": "306846046f78d632",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 inputs, 1000 labels\n",
      "800 train inputs, 800 train labels\n",
      "200 eval inputs, 200 eval labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train inputs': ['我想咨询一下做手术能好吗？手术怎么做，术后有后遗症吗？术后胃能不能长的和以前一样吗',\n",
       "  '排尿没有困难，就是口子太小龟头露不出来，用力撸还有点痛。',\n",
       "  '孙老师，您上次看过之后病好了，这两天肚子两侧又出现了微微凸起的红疙瘩，比较痒，依泉润肤霜我每天都抹2～3次，口服的药喝完了，外涂的药还有，我是不是再去医院找您看一下啊。孙老师，肚子两侧大概就是图片中的这个样子，我需要再喝点什么药吗？谢谢孙老师。',\n",
       "  '谢谢您的解答。',\n",
       "  '甲状腺结节。甲状腺结节微小钙化，血流丰富，定为4级，建议穿刺活检',\n",
       "  '今天吐了两次，要不要去医院',\n",
       "  '我已经去喉科检查过了，还做过消融治疗，但咳嗽问题仍然存在。',\n",
       "  '非常感谢医生的建议和祝福！我会按照您的指导去做的。',\n",
       "  '月经期推迟不准时，怀孕了右侧卵巢囊肿怎么办呢，现在呼吸有点难受',\n",
       "  '谢谢医生的解答。'],\n",
       " 'train labels': ['我了解您的担忧，手术是一种治疗胃下垂的方法，但是手术是否适合您，还需要进一步的评估。手术的具体方法和术后的后遗症会因个体差异而有所不同，所以我无法直接给出明确的答案。建议您咨询普外科医生，他们会根据您的具体情况进行评估，并给出最合适的治疗建议。手术后，胃的功能可能会有所改变，但是具体情况还需要医生根据您的病情来评估。',\n",
       "  '根据您的描述，这可能是包茎的症状。包茎是一种常见的男性生殖器问题，即包皮无法完全缩回露出龟头。建议您带孩子去医院进一步检查确认诊断。',\n",
       "  '根据您的描述，您可能出现了特应性皮炎的复发症状。不用担心，您可以继续使用依泉润肤霜，并在其基础上加上艾洛松软膏进行外用。这种药膏可以帮助缓解瘙痒和减轻炎症。不过，由于我无法看到您提到的图片，建议您再次使用外涂药物前，先来医院让我看一下，以确保正确的治疗方案。',\n",
       "  '不客气，希望我的回答对您有所帮助。如果还有其他问题，请随时向我提问。祝您和孩子健康！',\n",
       "  '对于您的情况，如果您已经决定进行手术，是否需要进行穿刺活检这个在不同医院可能会有不同的意见。对于您这种情况，如果能够通过穿刺活检进行病理确诊，那么在手术前进行一次穿刺是可以的。手术过程中不需要等待快速冰冻切片结果。如果是穿刺细胞学检查，个人认为手术过程中进行快速冰冻切片就足够了。如果您还在犹豫是否需要手术，想要更加明确情况，可以进行穿刺细胞学检查，不过这个方法并不是百分之百准确。根据您的情况，我建议：',\n",
       "  '了解到宝宝今天吐了两次，我可以给您一些建议。一般来说，两次呕吐并不一定需要立即去医院，但如果宝宝出现严重的脱水症状，如口渴、眼睛凹陷、尿量明显减少等，建议您及时就医。此外，如果宝宝的呕吐持续加重或伴随其他症状，如高热、持续腹泻等，也建议您咨询医生的意见。请您密切观察宝宝的病情变化，并根据宝宝的整体情况做出判断。如果您有任何进一步的疑问或需要帮助，请随时告诉我。',\n",
       "  '我理解你的困扰。慢性咽炎的诊断可能会因医生而异。根据你的描述，我认为你的症状与慢性咽炎相符。我自己也曾经患过慢性咽炎，虽然至今没有完全康复，但已经不再困扰我了。因此，我觉得以一个患者的身份与你交流可能更合适。首先，我想对你的情况表示理解，因为我也经历过类似的问题。慢性咽炎虽然不是什么大病，但确实很讨厌。尽管有很多治疗方法，但效果可能有限。有时候，甚至连我自己都觉得医学对此无能为力，呵呵，开个玩笑。但我们可以换个思路，不一定非要依赖药物或注射才能缓解症状，尤其是对于一些慢性疾病。就慢性咽炎而言，我个人的经验是，平时要注意保护嗓子，尽量少用嗓音，饮食要清淡，忌食生冷、辛辣和刺激性食物等。外出时，如果有雾天或大风天气，可以戴口罩等措施，这些都有助于改善咽部症状，尤其是减轻咽部异物感（总觉得有痰的感觉）。如果咽部不适，可以适量饮水（适当加热），小口慢慢地咽下去，这样异物感会减轻。此外，心理调节也非常重要。身体的不适，你越在意，不适感就会放大，你不在意，不适感就会减轻。这是身体主观感受的奇妙之处。综上所述，我的建议是，在不断求医问药之前，不妨在心理和生活方式上做出一些改变，看看会有什么效果。',\n",
       "  '不客气，希望我的建议对您有所帮助。如果您还有其他问题或需要进一步的帮助，请随时告诉我。祝您身体健康！',\n",
       "  '非常抱歉听到您的不适。首先，恭喜您怀孕了！您现在怀孕多少周了呢？',\n",
       "  '不客气，希望我的回答能够帮到您。如果您还有其他问题或需要进一步的帮助，请随时告诉我。祝您和您的孩子健康快乐！'],\n",
       " 'eval inputs': ['月经过去一天。下面又有点血。怎么回事。月经过去一天下面又有点血。怎么回事。最近几个月。月经都这样',\n",
       "  '冠状动脉粥样硬化多支病变冠心病。你好，我今年41岁，因胸痛入油田医院治疗，做心电图T波改变，心肌缺血，做心彩超和加强ct，诊断为冠状动脉粥样硬化多支病变，建议哎要时进行CAG及IVUS检查，左主干，左前降支，对角支及钝缘支见多发非钙化，钙化及混合斑块行成，官腔轻中度狭窄。入院半个月出院，有时还有疼痛的症状，西医建议做造影放支架，考虑年龄小不想做想找中医专家在好好看看',\n",
       "  '阴道炎。感觉白带有点多  乳白色  流到阴道口有点刺激痒，月经前后有异味',\n",
       "  '宝宝不是早产吧',\n",
       "  '高血压，但是应该是情绪化的高血压，近期一直都是140/100左右，前几天一进医院，血压一下就上180了。你好医生，我想看一下那个腹腔干开口处狭窄那个是怎么回事呢？严重吗？',\n",
       "  '好的，谢谢医生。我会注意保持健康的生活方式，并尽快前来医院面诊的。医生，再次感谢您的帮助。',\n",
       "  '有过一段时间阴道干，眼睛干，嘴唇干。皮肤现在很干，护肤品搽一遍不起作用，以前涂个水都足够。月经来的时候皮肤反而比较润一些',\n",
       "  '没有喔，之前医生没让检查。',\n",
       "  '现在是左侧耳朵里面下面疼，连着半边头疼，不闷，也不影响听力。疼的症状是持续的。但是今天疼痛比昨天有缓解，还没有用药',\n",
       "  '非常感谢您的解答，我会放心的。'],\n",
       " 'eval labels': ['很抱歉听到您的不适。根据您的描述，您可能正在经历一种叫做不规则出血的情况。有些人在月经结束后会出现少量的阴道出血，这在一定范围内是正常的。然而，如果您的月经一直不规律，建议您及时就医，以便医生进一步评估您的情况。',\n",
       "  '您好，根据您的描述，您被诊断为冠状动脉粥样硬化多支病变冠心病。这是一种血管狭窄的疾病，需要及时治疗以预防进一步的心脏问题。中医对于血管狭窄的治疗效果有限，因此我建议您尽早进行西医的介入治疗。这包括进行冠状动脉造影（CAG）和血管内超声（IVUS）检查，以评估狭窄的程度和位置。如果有必要，可以考虑放置支架来扩张狭窄的血管。这些治疗方法在现代医学中被广泛应用，可以帮助改善血液流动，减轻症状，并预防心脏事件的发生。',\n",
       "  '非常感谢您的信任，我已经详细阅读了您的病情描述。根据您提供的资料，我建议您是否曾经检查过阴道分泌物中的支原体和衣原体呢？',\n",
       "  '早产儿可能存在一些额外的健康风险，包括肺部发育不完全等。如果宝宝是早产儿，我们需要更加关注他的肺功能和健康状况。建议您向医生提供宝宝的早产情况，以便医生能够更好地评估宝宝的病情和制定治疗方案。',\n",
       "  '了解了，情绪化的高血压可能会导致血压波动较大。至于腹腔干开口处的狭窄，根据您提供的片子，目前并没有明显的狭窄情况。因此，不必过于担心。然而，高血压仍然是需要重视的，我们应该控制好血压，避免血压过高对身体造成的不良影响。',\n",
       "  '不客气，希望我的建议对您有所帮助。祝您早日康复，有一个健康愉快的生活。如果您有任何其他问题，随时都可以向我咨询。保持健康的生活方式，合理饮食，适度运动，保持心态平和，早睡早起，都是维持身体健康的重要因素。祝您身体健康，心情舒畅！',\n",
       "  '根据您的症状，我建议您到风湿免疫科进行唇腺活检，以明确是否患有干燥综合症。这种疾病会导致口干、眼干、阴道干燥等症状，同时也可能影响皮肤的水分平衡。活检结果将有助于确诊并制定相应的治疗方案。',\n",
       "  '了解。我建议您去泌尿外科进行检查，医生会给您开具检查精索静脉的单子。在检查前，您需要注意保持良好的生活习惯，避免过度劳累和性生活，以及避免过度紧张和焦虑。这些因素可能会对检查结果产生影响。',\n",
       "  '根据您的描述，您目前的症状是左侧耳朵里面下面疼，连着半边头疼，没有耳闷和听力受损的情况。疼痛是持续性的，但今天相比昨天有一定缓解，还没有使用药物对症处理。根据您之前的就诊情况，医生已经为您检查了耳朵和咽部，发现您的耳膜鼓起正常，但左侧有一点疼痛，诊断为分泌性中耳炎。医生给您开了地塞米松滴鼻剂、桉柠蒎和咽炎中成药。目前您没有鼻塞和流涕的症状。根据您的过敏体质，如果您对精油类过敏，建议不要使用桉柠蒎。至于地塞米松滴鼻剂，即使没有鼻塞和流涕的症状，也是需要使用的。关于是否需要进行其他耳鼻咽部检测，建议您在一周后的复诊时根据当时的情况再做决定，医生可能会建议您进行鼻内镜、耳内镜等检查。希望对您有所帮助。',\n",
       "  '非常感谢您的理解和信任。如果您还有其他问题或需要进一步的咨询，请随时告诉我。我将尽力为您提供帮助。祝您和胎儿健康！']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T03:18:40.977291Z",
     "start_time": "2024-10-10T03:18:39.673953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find batch size from train and eval set size\n",
    "from sympy import factorint\n",
    "from random import choice\n",
    "\n",
    "ADAPTIVE_TRAIN_BATCH_SIZE_SET = factorint(len(train_inputs), multiple=True, limit=MAX_BATCH_SIZE)\n",
    "ADAPTIVE_TRAIN_BATCH_SIZE = choice(ADAPTIVE_TRAIN_BATCH_SIZE_SET)\n",
    "while not (MIN_BATCH_SIZE <= ADAPTIVE_TRAIN_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS <= MAX_BATCH_SIZE):\n",
    "    ADAPTIVE_TRAIN_BATCH_SIZE = choice(ADAPTIVE_TRAIN_BATCH_SIZE_SET)\n",
    "ADAPTIVE_EVAL_BATCH_SIZE_SET = factorint(len(eval_inputs), multiple=True, limit=MAX_BATCH_SIZE)\n",
    "ADAPTIVE_EVAL_BATCH_SIZE = choice(ADAPTIVE_EVAL_BATCH_SIZE_SET)\n",
    "while not (MIN_BATCH_SIZE <= ADAPTIVE_EVAL_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS <= MAX_BATCH_SIZE):\n",
    "    ADAPTIVE_EVAL_BATCH_SIZE = choice(ADAPTIVE_EVAL_BATCH_SIZE_SET)\n",
    "{\n",
    "    'train_batch_size_set': ADAPTIVE_TRAIN_BATCH_SIZE_SET,\n",
    "    'eval_batch_size_set': ADAPTIVE_EVAL_BATCH_SIZE_SET,\n",
    "    'train batch size': ADAPTIVE_TRAIN_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS, \n",
    "    'eval batch size': ADAPTIVE_EVAL_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS\n",
    "}"
   ],
   "id": "63686df336fa7d2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_batch_size_set': [2, 2, 2, 2, 2, 5, 5],\n",
       " 'eval_batch_size_set': [2, 2, 2, 5, 5],\n",
       " 'train batch size': 80,\n",
       " 'eval batch size': 32}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T03:33:14.732405Z",
     "start_time": "2024-10-10T03:18:44.879111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, cache_dir='./cache')\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, cache_dir='./cache')\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "lora_model.print_trainable_parameters()"
   ],
   "id": "c0c7c3b12d8b7782",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96ccecf6a83f498bb5ffb2b5c8e98e57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "735e2146aab14df5862cff29914ed273"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "989d02a541d5490a81286d6aff8c42e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6247c9fc1b1c43288497a45209c0b424"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dab908e7ec404054a85621baa9cc1f38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2eb4aa694fc7462f9ccc7d6bb944d558"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d798474a6cf1435b8f0b32375a96ea4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 540,672 || all params: 494,573,440 || trainable%: 0.1093\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T03:33:15.208098Z",
     "start_time": "2024-10-10T03:33:14.739516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare train data\n",
    "from datasets import Dataset\n",
    "\n",
    "max_len = MAX_TENSOR_DIM\n",
    "tokenized_train_inputs = tokenizer(\n",
    "    train_inputs, \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "tokenized_train_labels = tokenizer(\n",
    "    train_labels, \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "tokenized_eval_inputs = tokenizer(\n",
    "    eval_inputs, \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "tokenized_eval_labels = tokenizer(\n",
    "    eval_labels, \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "train_dataset_raw = {\n",
    "    'input_ids': tokenized_train_inputs['input_ids'],\n",
    "    'attention_mask': tokenized_train_inputs['attention_mask'],\n",
    "    'labels': tokenized_train_labels['input_ids']\n",
    "}\n",
    "eval_dataset_raw = {\n",
    "    'input_ids': tokenized_eval_inputs['input_ids'],\n",
    "    'attention_mask': tokenized_eval_inputs['attention_mask'],\n",
    "    'labels': tokenized_eval_labels['input_ids']\n",
    "}\n",
    "train_dataset = Dataset.from_dict(train_dataset_raw)\n",
    "eval_dataset = Dataset.from_dict(eval_dataset_raw)\n",
    "{'train_dataset': train_dataset_raw,'eval_dataset': eval_dataset_raw}"
   ],
   "id": "1e3db1c69e87be63",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset': {'input_ids': tensor([[104100, 100703, 100158,  ..., 151643, 151643, 151643],\n",
       "          [ 59956, 102395,  80443,  ..., 151643, 151643, 151643],\n",
       "          [100685, 101049,   3837,  ..., 102201,  99486,  45930],\n",
       "          ...,\n",
       "          [ 80443,  99190, 100654,  ..., 151643, 151643, 151643],\n",
       "          [102570, 103998, 111423,  ..., 151643, 151643, 151643],\n",
       "          [106287,   3837,  35946,  ..., 151643, 151643, 151643]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]]),\n",
       "  'labels': tensor([[ 35946,  99794, 101214,  ..., 101898,   1773, 104160],\n",
       "          [100345, 101214,  53481,  ..., 151643, 151643, 151643],\n",
       "          [100345, 101214,  53481,  ...,  47815, 100286, 104459],\n",
       "          ...,\n",
       "          [100345, 101214,  53481,  ...,   3837, 105705,  99727],\n",
       "          [ 16530, 112221,   3837,  ..., 151643, 151643, 151643],\n",
       "          [102570, 103929, 101128,  ..., 151643, 151643, 151643]])},\n",
       " 'eval_dataset': {'input_ids': tensor([[110362, 100688, 100729,  ..., 151643, 151643, 151643],\n",
       "          [ 99704,  99762, 109826,  ...,  13343,  71817,     34],\n",
       "          [112829, 100439,   1773,  ..., 151643, 151643, 151643],\n",
       "          ...,\n",
       "          [108166, 101111,  36587,  ..., 151643, 151643, 151643],\n",
       "          [110151, 113021, 100876,  ..., 151643, 151643, 151643],\n",
       "          [109194, 104160,  20412,  ..., 151643, 151643, 151643]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]]),\n",
       "  'labels': tensor([[ 99165, 115546, 104188,  ..., 151643, 151643, 151643],\n",
       "          [111308,   3837, 100345,  ...,  66078,  57222,   9909],\n",
       "          [ 99491, 104305, 101214,  ..., 151643, 151643, 151643],\n",
       "          ...,\n",
       "          [ 20412,   9370,   3837,  ..., 151643, 151643, 151643],\n",
       "          [110151, 113021, 100876,  ..., 105920, 104086, 102188],\n",
       "          [104160,  44063,  67071,  ..., 151643, 151643, 151643]])}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    use_cpu=True,\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=ADAPTIVE_TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=ADAPTIVE_EVAL_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    log_level='info',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=16,\n",
    "    logging_strategy='steps',\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=16,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=16,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ").train()"
   ],
   "id": "22098b4e73b87304",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save\n",
    "lora_model.save_pretrained(f'./model/{SFT_MODEL}')"
   ],
   "id": "4e6ddf61f42358b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test\n",
    "model = AutoModelForCausalLM.from_pretrained(f'./model/{SFT_MODEL}')\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe('足部骨折。你好大夫，谢谢您百忙中的时间。请问骨折对位可以吗？内侧契骨是稍有错位吗？') # 您好，我很高兴能为您提供帮助，根据您的描述，骨折的对位情况还可以。但是，为了更准确地评估情况，我是否可以看一下术前的片子呢？"
   ],
   "id": "c6ad52310e40790b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
