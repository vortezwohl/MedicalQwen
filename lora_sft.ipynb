{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-09T08:39:56.761698Z",
     "start_time": "2024-10-09T08:39:53.482956Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "disc_med_sft = load_dataset(\"Flmc/DISC-Med-SFT\", cache_dir='./cache')['train']"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:40:00.388270Z",
     "start_time": "2024-10-09T08:40:00.383531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# peek\n",
    "disc_med_sft"
   ],
   "id": "ca6aba3069d0cc75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'source', 'conversation'],\n",
       "    num_rows: 464898\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:43:32.488013Z",
     "start_time": "2024-10-09T08:43:07.537680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inputs = list[str]()\n",
    "labels = list[str]()\n",
    "conversation_pair = list[tuple]()\n",
    "conversations_trunks = disc_med_sft['conversation']\n",
    "conversations_trunk = list[dict]()\n",
    "for conversation_trunk in conversations_trunks:\n",
    "    for a_conversation in conversation_trunk:\n",
    "        conversations_trunk.append(a_conversation)\n",
    "conversations = list[dict]()\n",
    "for index, conversation in enumerate(conversations_trunk):\n",
    "    if conversation['role'] == 'user':\n",
    "        conversations.append((conversation, conversations_trunk[index + 1]))\n",
    "for conversation in conversations:\n",
    "    inputs.append(conversation[0]['content'])\n",
    "    labels.append(conversation[1]['content'])\n",
    "print(f'{len(inputs)} inputs, {len(labels)} labels')\n",
    "train_inputs, train_labels, eval_inputs, eval_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "{\n",
    "    'train inputs': train_inputs[:10],\n",
    "    'train labels': train_labels[:10],\n",
    "    'eval inputs': eval_inputs[:10],\n",
    "    'eval labels': eval_labels[:10],\n",
    "}"
   ],
   "id": "306846046f78d632",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385471 inputs, 1385471 labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train inputs': ['谢谢陈医生热心解答，想再次求教您一下。像我这样长期手淫或类前列腺炎症状，有没有可能对未来的子女造成出生缺陷或智力低下？',\n",
       "  '谢谢医生的解答，我会按照您的建议去做检查的。',\n",
       "  '宝宝可能是用手揉了眼睛，患眼外眼角眼白红了，有许多红色的血丝，问题大不大，就用托百士药水，贝复舒凝胶，托百士膏，可以解决问题吗。可以解决的话，用法上还是一天3次，晚上多点几次药膏吗，需要调整吗。麻烦您了于主任，期盼您的答复，谢谢。昨天晚上没有看好孩子，宝宝可能是用手揉了眼睛，患眼外眼角眼白红了，有许多红色的血丝，这个怎么办啊。目前用的托百士药水，贝复舒凝胶，托百士膏就这3种药可以解决问题吗，用法需要调整吗。麻烦您了于主任，期盼您的回复，谢谢',\n",
       "  '谢谢医生的建议。',\n",
       "  '你好门医生，可以注射骨水泥吗？需要做什么检查？',\n",
       "  '肺水肿能治好吗，同时患有高血压和糖尿病。忽然喘气困难',\n",
       "  '凭你的 经验 这初步认为什么毛',\n",
       "  '脂溢脱发。产后6个多月开始拔罐减肥，饮食单一，1个多月的时间里减了18斤，产后9个多月开始脱发，晚睡，大便干，晚尿最少有1到2次，掉头到现在有2个月时间己掉了一半了。',\n",
       "  '那如何可以排除！还是怎样确诊？',\n",
       "  '我是办公室工作，每天长时间坐着。工作压力确实有点大。'],\n",
       " 'train labels': ['这个...',\n",
       "  '我没有舌苔照片，但我可以描述一下我的舌苔情况吗？',\n",
       "  '医生，我听说椎管狭窄会导致双下肢沉重症状，您觉得我这种情况可能是梨状肌综合征吗？我可以携带检查结果来贵院住院治疗吗？',\n",
       "  '我之前做过超声检查，可以提供给您参考吗？',\n",
       "  '怀孕初期，各项数值低，想保胎。末次月经2015年11月1日，打了破卵针后，11月21日排卵，12月8日查出怀孕，抽血绒促62.9miu/ml，孕酮11.765ng/ml，雌二醇266pg/ml。医生开了黄体酮，地屈孕酮片和参茸保胎丸，12月10日复查，孕酮涨到27，雌二醇涨到300，但绒促增长很慢，才99。12月14日复查，绒促涨到342，孕酮30，雌二醇降到154。医生说不好，让停药，停药后12月18日复查，绒促只涨到532，孕酮降到5.57，雌二醇降到113。12月18日做B超，显示宫内见稍强回声伴小无回声，直径2mm',\n",
       "  '牙周炎，牙龈萎缩。牙龈萎缩，牙周炎，找不到病因。目前口腔还有炎镇',\n",
       "  '是否有压力焦虑。有无熬夜劳累。',\n",
       "  '谢谢医生的回答。那我现在应该如何应对我的抑郁症呢？',\n",
       "  '谢谢医生的建议。',\n",
       "  '非常感谢医生的解答！'],\n",
       " 'eval inputs': ['根据目前的医学研究，长期手淫或前列腺炎症状一般不会对未来的子女造成出生缺陷或智力低下。然而，如果您计划要孩子，建议您在备孕前进行全面的身体检查，以确保身体状况良好，减少潜在的风险。同时，保持良好的生活习惯和均衡的饮食对于健康的生育也非常重要。\\n不过，我还是强烈建议您尽快到医院进行检查，以便明确诊断和制定相应的治疗方案。及早治疗可以有效缓解症状，预防疾病的进一步发展。如果您有任何其他问题，我会尽力为您解答。',\n",
       "  '肝炎，检查方法：上腹部CT平扫加增强，剑突基线，层厚7.5mm，pitch1.375:1，共120层，造影剂：欧乃派克300mgI/ml共100ml影像表现：肝脏形态大小正常，CT值40Hu，右叶后下段可见动脉期类圆形略高密度影，直径约1.7cm，门脉期呈相对高密度影，延迟期呈高密度影；肝静脉汇入下腔静脉区可见类圆形脂性密度影，直径约1.7cm，未见明显强化。胆囊形态大小正常，未见明显密度影，脾脏体积未见明显增大，增强后扫描未见明显异常密度影，胰腺形态大小正常，未见异常密度影，双肾点状高密度影，腹膜后未见异常增大的淋巴结血液化验单：HBsAg:阳性抗-HBe:阴性抗-HBS:阴性抗-HBo:阳性HBeAg:阳性1.丙氨酸转氨酶:(ALT):33参考值:0-412.天冬氨酸转氨酶:(AST):28参考值:0-403.碱性磷酸酶:(ALP):95参考值:39-1204.总胆红素:(T.BIL1)24.2参考值:2-205.直接胆红素:(D.BIL1):3.1参考值:0-66.总蛋',\n",
       "  '非常抱歉，之前的回答可能没有解答到您的问题。对于宝宝眼睛红肿的情况，您可以继续使用托百士药水、贝复舒凝胶和托百士膏，这些药物可以缓解眼部不适。一般来说，使用药水的频率是一天3次，如果需要使用药膏，可以在晚上多点几次。具体的用法和频率还是要根据医生的建议为准。如果症状没有明显改善或持续加重，请及时与医生联系。希望这次能够解答到您的问题，如果还有其他疑问，请随时告诉我。\\n已经回复',\n",
       "  '乙肝，本人男性，小三阳，治疗前DNA肝功能不正常。妻子正常有抗体',\n",
       "  '了解到您对注射骨水泥的治疗方法感兴趣。在决定是否进行注射之前，我们需要进一步评估您的情况。最好先进行磁共振检查，以便更全面地了解您的骨折情况和周围组织的状况。这将有助于我们确定是否适合进行骨水泥注射治疗，并预测治疗效果。建议您与您的主治医生讨论，并安排相应的检查。',\n",
       "  '您好，非常抱歉听到您的不适。肺水肿通常是由冠心病心功能衰竭或肾功能衰竭引起的。而高血压和糖尿病可能导致全身动脉硬化和靶器官损害，如糖尿病肾病、冠心病和脑中风等。为了更好地了解您的病情，请提供更多的病史信息，如心脏彩超、胸片和血气分析等。另外，您的心肝肾功能指标如何呢？',\n",
       "  '根据您的症状描述，如果两个手掌都有这样的情况，首先应该考虑湿疹的可能性较大。湿疹是一种慢性炎症性皮肤病，常常会出现红疙瘩、瘙痒、水泡和脱皮等症状。但最终的诊断还需要通过医院的检查来确定。',\n",
       "  '您好，我了解您的情况。产后脱发是很常见的现象，而急性减肥也可能导致脱发。根据您的描述，您可能正在经历休止期脱发。为了更好地帮助您，能否提供一张头发的照片让我更好地判断呢？谢谢。',\n",
       "  '为了确诊结核感染，我们通常会进行结核感染T细胞实验和干扰素释放实验。',\n",
       "  '明白了，长时间坐着可能会导致胃肠蠕动减慢，增加胃胀气的风险。此外，工作压力过大也可能对消化系统产生不良影响。为了缓解胃胀气的症状，我建议您注意以下几点：\\n1. 规律饮食：尽量避免辛辣、油腻、过饱或过快进食，保持饮食的多样性和均衡性。\\n2. 少量多餐：每餐食量适中，可以考虑增加餐次，减少单次进食量，有助于减轻胃部负担。\\n3. 注意姿势：长时间坐着时，尽量保持良好的坐姿，避免驼背或过度弯腰，可以适当站起来活动一下。\\n4. 放松压力：工作压力大时，可以尝试一些放松的方法，如深呼吸、休息片刻或进行适量的运动等。\\n\\n如果您的症状持续存在或加重，建议您及时就医，进行进一步的检查和治疗。希望我的建议对您有所帮助。如果还有其他问题，请随时告诉我。'],\n",
       " 'eval labels': ['根据您提供的信息，孩子的脐疝比较大，但目前还不建议手术。您可以考虑给孩子买一个脐疝带，用于压迫脐疝，避免其凸出过大，影响肠道蠕动。如果孩子到了半岁活动多的时候脐疝带戴不住，可以考虑手术修补。',\n",
       "  '当然可以，请您详细描述一下您的舌苔情况，包括颜色、厚度、湿润程度等方面的特征。',\n",
       "  '根据您的症状描述，椎管狭窄可能导致双下肢沉重症状。同时，您提到的左脚及左下肢麻木、左脚不由自主弓形抽和左臀部稍有麻木的症状也与梨状肌综合征有关。为了进一步明确诊断，我建议您携带检查结果来我院进行住院治疗。我们将进行详细的检查和评估，并制定相应的治疗方案，包括牵引、按摩等保守治疗。',\n",
       "  '非常感谢您提供的超声检查结果。我会结合您的病史和临床表现进行综合分析。如果您有其他相关检查结果，也请一并提供，以便更好地评估您的病情。',\n",
       "  '根据您提供的信息，您的孕酮水平大于5，说明您仍然可以继续保胎。建议在hcg大于1万的时候再进行超声检查，以便更准确地判断胎儿的情况。',\n",
       "  '您好，很高兴为您提供帮助。牙周炎和牙龈萎缩可能有多种原因引起，包括口腔卫生不良、牙齿刷洗不当、牙结石等。除了这些因素，身体其他疾病也可能对口腔健康产生影响。所以我想了解一下您是否有其他疾病呢？',\n",
       "  '了解。压力和焦虑可能会对血压产生一定的影响。如果您感到有些忧虑，这可能会导致血压稍微升高。另外，长时间的熬夜和劳累也可能对血压产生一定的影响。建议您保持良好的心态，避免过度紧张和疲劳，有助于维持血压的稳定。',\n",
       "  '抑郁症在孕期是比较常见的心理问题，但是请不要担心，我们会尽力帮助您。首先，建议您与家人和朋友分享您的感受，他们的支持和理解会对您有很大的帮助。此外，保持积极的生活态度，参加一些适合孕妇的活动，如孕妇瑜伽或散步，有助于缓解情绪。如果您的抑郁症状持续严重，影响到您的日常生活，我建议您咨询专业的心理咨询师或心理医生，他们会给您提供更具体的帮助和支持。',\n",
       "  '不客气，祝您身体健康！如果还有其他问题，随时向我咨询。',\n",
       "  '高危后68天化学发光法。68天艾滋抗体阴。血常规白细胞降低。淋巴细胞上升。嗜酸细胞和中粒细胞下降。医生说是病毒感染。近一周出现低烧和皮疹。目前可以的阴性有意义吗？会不会有转阳的可能？']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:38:05.851223Z",
     "start_time": "2024-10-09T08:37:53.128582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_checkpoint = \"Qwen/Qwen2.5-0.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\", cache_dir='./cache')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, cache_dir='./cache')\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "lora_model.print_trainable_parameters()"
   ],
   "id": "c0c7c3b12d8b7782",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 540,672 || all params: 494,573,440 || trainable%: 0.1093\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:46:31.393276Z",
     "start_time": "2024-10-09T08:46:31.348820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare train data\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "max_len = 68\n",
    "max_size = 10\n",
    "tokenized_train_inputs = tokenizer(\n",
    "    train_inputs[:max_size], \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "tokenized_train_labels = tokenizer(\n",
    "    train_labels[:max_size], \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "tokenized_eval_inputs = tokenizer(\n",
    "    eval_inputs[:max_size], \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "tokenized_eval_labels = tokenizer(\n",
    "    eval_labels[:max_size], \n",
    "    padding='max_length',\n",
    "    max_length=max_len,\n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "train_dataset_raw = {\n",
    "    'input_ids': tokenized_train_inputs['input_ids'],\n",
    "    'attention_mask': tokenized_train_inputs['attention_mask'],\n",
    "    'labels': tokenized_train_labels['input_ids']\n",
    "}\n",
    "eval_dataset_raw = {\n",
    "    'input_ids': tokenized_eval_inputs['input_ids'],\n",
    "    'attention_mask': tokenized_eval_inputs['attention_mask'],\n",
    "    'labels': tokenized_eval_labels['input_ids']\n",
    "}\n",
    "train_dataset = Dataset.from_dict(train_dataset_raw)\n",
    "eval_dataset = Dataset.from_dict(eval_dataset_raw)\n",
    "{'train_dataset': train_dataset_raw,'eval_dataset': eval_dataset_raw}"
   ],
   "id": "1e3db1c69e87be63",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset': {'input_ids': tensor([[102570, 100348, 103998, 110576, 106185,   3837,  99172, 103989,  30918,\n",
       "            99182,  87026, 100158,   1773,  65101,  35946,  99654, 101930,  44934,\n",
       "           108673,  57191,  21515, 116019, 100439, 101368,   3837, 104710,  87267,\n",
       "            32664, 105735, 105376, 101090, 102246, 106136,  57191, 107941, 111616,\n",
       "            11319, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [102570, 103998,   9370, 106185,   3837, 105351, 101892, 101214, 101898,\n",
       "           105715, 101071,   9370,   1773, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [102000, 104560, 108262, 107775,  34187, 104171,   3837,  99811,  99246,\n",
       "            47815, 116908,  99246,  99243,  99425,  34187,   3837, 107273, 104165,\n",
       "             9370,  99389,  99691,   3837,  86119,  26288, 105378,   3837,  80158,\n",
       "            11622,  99829,  99271,  99253,  99471,  52510,   3837, 100458,  58364,\n",
       "           100285, 100898, 100773,   3837,  99829,  99271,  99253, 103143,   3837,\n",
       "            73670, 107124, 101037,   1773,  73670, 100638, 100363,   3837,  11622,\n",
       "            24339,  17447,  97706,  99639,  35727,     18,  32571,   3837, 104030,\n",
       "            42140,  27442, 106065,  99471, 103143],\n",
       "          [102570, 103998,   9370, 101898,   1773, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [108386,  64689, 103998,   3837,  73670, 107833, 100049, 104948, 101037,\n",
       "            11319,  85106, 106428, 101071,  11319, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [100887, 117908,  26232,  69905, 110201,   3837,  91572, 110088, 109155,\n",
       "            33108, 107218,   1773, 105420, 103425,  99180, 103985, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [100284, 103929,  44054,    237,  41362,  32181,    247, 105185, 100140,\n",
       "            99245,  99676, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [100553, 102764, 114537,   1773, 109594,     21, 114178,  55286, 101355,\n",
       "           105240, 105026,   3837, 104579, 106215,   3837,     16, 114178, 113468,\n",
       "            99536,  34187,     16,     23, 102374,   3837, 109594,     24, 114178,\n",
       "            55286, 114537,   3837,  99438, 100425,   3837,  26288,  99364,  99251,\n",
       "             3837,  99438, 102395, 110640,  18830,     16,  26939,     17,  32571,\n",
       "             3837, 100373,  64355, 105964,  18830,     17,  99943,  20450,  99270,\n",
       "           100373,  99593,  99369,  34187,   1773, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [ 99212, 100007,  73670, 102945,   6313,  99998, 102066, 103207,  11319,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [104198, 104113,  99257,   3837, 101922, 102612, 110455,   1773,  99257,\n",
       "           101950, 102068, 104037,  26288,   1773, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "  'labels': tensor([[ 99487,   1112, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [108763, 101601, 114144, 102184,   3837, 105984,  73670,  53481, 100158,\n",
       "            97611, 101601, 114144,  99559, 101037,  11319, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [103998,   3837,  35946, 102654, 103789,  35551, 114494, 107191,  99493,\n",
       "            16872, 101775, 109370, 101368,   3837,  87026,  99801,  35946, 106334,\n",
       "           104560, 105914,  99762, 101408, 118458, 101037,  11319, 109944, 107426,\n",
       "           101071,  59151,  36407,  99582,  93823, 107594, 101899, 101037,  11319,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [ 35946, 101056, 107994,  71304,  70074, 101071,   3837,  73670,  99553,\n",
       "           111998, 101275, 101037,  11319, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [105432, 105225,   3837, 101298, 111944,  99285,   3837,  99172,  32463,\n",
       "           100521,   1773, 100072,  32571, 110362,     17,     15,     16,     20,\n",
       "             7948,     16,     16,   9754,     16,   8903,   3837, 106677,  99577,\n",
       "           101574, 100179,  33447,   3837,     16,     16,   9754,     17,     16,\n",
       "             8903,  59956, 101574,   3837,     16,     17,   9754,     23,   8903,\n",
       "            32876,  20221, 105432,   3837,  99950,  99389, 108040, 100028,     21,\n",
       "               17,     13,     24,   8155,     84,  59548,   3837,  99983, 112437,\n",
       "               16,     16,     13,     22,     21],\n",
       "          [100446,  40542, 100439,   3837, 100446, 121403, 112821,   1773, 100446,\n",
       "           121403, 112821,   3837, 100446,  40542, 100439,   3837, 106486, 113422,\n",
       "             1773, 100004, 107005, 100626, 100439,  99523, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [107189, 101950, 107115,   1773,  18830,  42192, 113414, 118945,   1773,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [102570, 103998, 111423,   1773,  99212, 107520, 112741, 104397,  97611,\n",
       "           115496, 101036,  11319, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [102570, 103998,   9370, 101898,   1773, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [ 99491, 104305, 103998,   9370, 106185,   6313, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643]])},\n",
       " 'eval_dataset': {'input_ids': tensor([[100345, 100004,   9370, 104316,  99556,   3837, 101930,  44934, 108673,\n",
       "            57191, 116019, 100439, 101368, 100141,  99670,  32664, 105735, 105376,\n",
       "           101090, 102246, 106136,  57191, 107941, 111616,   1773, 103968,   3837,\n",
       "           106870, 101039,  30534,  99657,   3837, 101898,  87026,  18493,  56278,\n",
       "            99983,  24562, 115746, 106214, 101071,   3837,  23031, 103944, 101099,\n",
       "           104215, 100844,   3837, 101940, 106362, 106066,   1773,  91572,   3837,\n",
       "           100662, 104205, 114781,  33108, 107101,   9370, 104579, 100002, 108136,\n",
       "           103042,  74763, 106078,   8997, 100632],\n",
       "          [101364, 100439,   3837, 101071,  39907,   5122,  17447, 110151,   1162,\n",
       "            49111,  99864,  20929, 101138,   3837, 103954,  99624,  74046,  43268,\n",
       "             3837,  99371,  99696,     22,     13,     20,   3821,   3837,  53238,\n",
       "               16,     13,     18,     22,     20,     25,     16,   3837,  54899,\n",
       "               16,     17,     15,  99371,   3837,  66078,  57222, 100067,   5122,\n",
       "            99831, 101451,  99890,  99316,     18,     15,     15,  12311,     40,\n",
       "            59548,  54899,     16,     15,     15,   1014, 106693, 101107,   5122,\n",
       "           112506, 102533,  92032, 100416,   3837],\n",
       "          [ 99491, 115546,   3837, 108355, 102104,  87267,  80443, 106185,  26939,\n",
       "           101214,  86119,   1773, 100002, 102000, 104171,  99425, 101561, 102072,\n",
       "             3837, 107952, 100640,  37029,  99829,  99271,  99253,  99471,  52510,\n",
       "             5373, 100458,  58364, 100285, 100898, 100773,  33108,  99829,  99271,\n",
       "            99253, 103143,   3837, 100001, 104459,  73670, 105002, 113948, 108684,\n",
       "             1773, 109691,   3837,  37029,  99471,  52510,   9370, 107586,  99639,\n",
       "            35727,     18,  32571,   3837,  62244,  85106,  37029,  99471, 103143,\n",
       "             3837, 104964, 104030,  42140,  27442],\n",
       "          [116898,   3837, 102043, 105106,   3837,  30709,  44991,  82075,   3837,\n",
       "           101899,  24562,  55320, 101364,  98380,  16530, 100416,   1773, 102375,\n",
       "           100416,  18830, 116473, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [104958,  87026,  32664, 107833, 100049, 104948,   9370, 114464, 103198,\n",
       "             1773,  18493, 103930,  64471,  71817, 107833, 101056,   3837, 109202,\n",
       "           100642, 102086, 101214,  99559,   1773, 101171,  60726,  71817, 101459,\n",
       "           117682, 101071,   3837, 105920,  33126, 100011,  29490,  99794, 101214,\n",
       "           112460,  99559,  33108, 102385,  99877,   9370, 104215,   1773,  43288,\n",
       "            44063, 105767,  97639,  60610,  64471, 100231,  71817, 100049, 104948,\n",
       "           107833, 101899,  90395, 104538, 101899, 101062,   1773, 101898,  87026,\n",
       "            57218, 101214, 117780, 103998, 104075],\n",
       "          [111308,   3837,  99491, 115546, 104188, 101214, 108684,   1773, 100887,\n",
       "           117908, 102119, 104625,  99704,  63109,  99252,  63109,  98380, 101557,\n",
       "           109621,  57191, 102512,  98380, 101557, 109621, 107503,   1773,  68536,\n",
       "           109155,  33108, 107218, 116505, 105418, 109826, 111328,  33108, 112073,\n",
       "           108022, 105252,   3837,  29524, 107218, 102512,  99252,   5373,  99704,\n",
       "            63109,  99252,  33108,  99931,  15946,  99208,  49567,   1773, 100012,\n",
       "           105344,  99794, 101214, 106141,  37945,  99553, 102075,  99252,  99497,\n",
       "            27369,   3837,  29524, 103023,  99414],\n",
       "          [100345, 101214, 101368,  53481,   3837,  62244, 100369, 113856, 101103,\n",
       "           101893,  99559,   3837, 101140,  99730, 101118, 100102, 113908, 107271,\n",
       "           104590,   1773, 100102, 113908, 101158, 108044, 110819,  33071, 116771,\n",
       "             3837, 104495, 105609,  99425, 119338, 119475,   5373, 121488, 108681,\n",
       "             5373,  52510, 100454,  33108,  99694,  99888, 115969,   1773,  77288,\n",
       "           103941,   9370, 105262, 106750,  67338, 100634,   9370, 101071,  36407,\n",
       "            60610,   1773, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [111308,   3837,  35946,  99794, 101214,  99559,   1773, 109594, 114537,\n",
       "           105391, 102716, 102060,   3837,  68536, 109689, 105026, 108542, 100673,\n",
       "           114537,   1773, 100345, 101214,  53481,   3837,  87026,  87267,  96555,\n",
       "           100798, 100242,  81433,  22704, 114537,   1773, 100012, 105344, 100364,\n",
       "            87026,   3837, 105095,  99553, 104298, 104994, 107344, 104029, 105344,\n",
       "           104317, 101036,  11319, 102570,   1773, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [100012, 103207,  36885,  71137, 101304,   3837,  97639, 102119,  36993,\n",
       "            71817,  36885,  71137, 101304,     51, 102150, 102140,  33108, 107696,\n",
       "            71138, 104739, 102140,   1773, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [108449,   3837, 102612, 110455, 104309, 100673, 113385, 119526,  27733,\n",
       "            99536,  99843,   3837, 100649, 100518, 101790,  99180, 106066,   1773,\n",
       "           104043,   3837,  99257, 101950, 111369, 108542,  32664, 105251,  72448,\n",
       "           100394, 102366,  99564,   1773, 100012, 105002, 100518, 101790,  99180,\n",
       "           111492,   3837,  35946, 101898,  87026,  60533,  87752, 112224,  28311,\n",
       "               16,     13,  54955,    226,  99499, 104579,   5122, 104638, 101153,\n",
       "           118970,   5373, 116791,   5373,  38182, 100962,  57191,  38182,  99234,\n",
       "           115737,   3837, 100662, 104579,   9370]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       "  'labels': tensor([[100345,  87026, 103008,  27369,   3837, 104661, 113926, 119938, 108969,\n",
       "             3837,  77288, 100004, 101558, 101898, 104160,   1773, 107952, 101118,\n",
       "           108098,  99565,  46944, 113926, 119938,  99278,   3837, 100751, 115025,\n",
       "           113926, 119938,   3837, 101153,  41146, 103179,  20221, 111369,   3837,\n",
       "            99564, 113217, 119526,  27733,   1773,  62244,  99657,  99495,  99369,\n",
       "            92015,  99600,  42140, 103920, 113926, 119938,  99278, 100469, 102363,\n",
       "             3837,  73670, 101118, 104160, 117255,   1773, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [103942,  73670,  37945,  87026, 100700,  53481, 100158, 101214, 101601,\n",
       "           114144,  99559,   3837, 100630, 102284,   5373, 109403,   5373, 116442,\n",
       "           100069, 108515, 104363,   1773, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [100345, 101214, 101368,  53481,   3837, 103789,  35551, 114494, 116505,\n",
       "            99493,  16872, 101775, 109370, 101368,   1773,  91572,   3837,  87026,\n",
       "           104496,   9370,  77559, 100037,  81217,  77559,  16872, 101775, 117949,\n",
       "             5373,  77559, 100037, 103498, 100842, 107955,  82699,  99950,  33108,\n",
       "            77559, 117318,  32948,  93266,  18830, 117949, 111492,  74763,  57218,\n",
       "           105914,  99762, 101408, 118458, 101063,   1773, 100012, 100642, 100692,\n",
       "           105262,   3837,  35946, 101898,  87026, 107426, 101071,  59151,  36407,\n",
       "           113401,  71817, 107594, 101899,   1773],\n",
       "          [ 99491, 104305,  87026, 103008,  71304,  70074, 101071,  59151,   1773,\n",
       "           105351, 100374, 101214,  99252,  99497,  33108, 104595, 101107,  71817,\n",
       "            99799, 101042,   1773, 106870,  18830,  92894,  78556, 101071,  59151,\n",
       "             3837,  74763,  14880,  14777,  62926,  99553,   3837, 105920, 105344,\n",
       "           102086, 101214, 106141,   1773, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [100345,  87026, 103008,  27369,   3837, 101214,  99983, 112437, 100021,\n",
       "           107043,     20,   3837,  66394,  87026, 104187,  73670, 100640,  32463,\n",
       "           100521,   1773, 101898,  18493,     71,  27446, 107043,     16,  31207,\n",
       "           103920,  87256,  71817,  71304,  70074, 101071,   3837, 105920,  33126,\n",
       "           102188,  29490, 104317, 109178, 102072,   1773, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [111308,   3837, 112169, 113445, 100364,   1773, 100446,  40542, 100439,\n",
       "            33108, 100446, 121403, 112821,  87267,  18830, 101312,  99917, 100771,\n",
       "             3837, 100630, 107005, 100200, 102366,   5373, 107453, 101210,  99634,\n",
       "           108486,   5373, 100446, 113801,  49567,   1773, 103931, 100001, 100741,\n",
       "             3837, 101099,  92894, 101160, 108542,  32664, 107005,  99722, 100394,\n",
       "            99564,   1773,  99999, 104100, 110050,  87026, 107189,  92894, 101160,\n",
       "           101036,  11319, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [ 99794,   1773, 101950,  33108, 107115, 104309,  32664, 103285, 100394,\n",
       "           102495,  99564,   1773, 106870, 104048, 101895, 117366,   3837,  43288,\n",
       "           104309, 100673, 103285, 106683, 109061,   1773, 101948,   3837, 102612,\n",
       "             9370, 113414,  33108, 118945, 108542,  32664, 103285, 100394, 102495,\n",
       "            99564,   1773, 101898,  87026, 100662, 104205, 106479,   3837, 101153,\n",
       "           105831, 104432,  33108, 108351,   3837, 105767, 104601, 103285,   9370,\n",
       "           100407,   1773, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [115496,  18493, 115898, 110726, 102716, 100438,  86119,   3837, 100131,\n",
       "            14880, 100148, 102142,   3837, 107233, 110121, 100364,  87026,   1773,\n",
       "           101140,   3837, 101898,  87026,  57218, 104271,  33108,  99614,  93149,\n",
       "           101214, 101224,   3837, 104056, 100143,  33108, 101128, 108772,  87026,\n",
       "           109711, 100364,   1773, 104043,   3837, 100662,  99666, 104103, 102316,\n",
       "             3837, 101061, 101883, 100231, 107251,   9370,  99600,   3837,  29524,\n",
       "           107251, 111630,  57191, 111261,   3837, 105767, 105002, 104405,   1773,\n",
       "            62244, 101214, 103677, 101368, 100652],\n",
       "          [ 16530, 112221,   3837, 100549,  87026, 108562,   6313,  62244, 100626,\n",
       "            92894,  86119,   3837, 102422,  69041,  35946, 100703,   1773, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "           151643, 151643, 151643, 151643, 151643],\n",
       "          [ 44636, 100087,  33447,     21,     23,  35727, 102264, 111663,  24339,\n",
       "             1773,     21,     23,  35727, 114166, 116473, 100205,   1773,  99389,\n",
       "           106307,  99243, 102150, 101134,   1773, 114814, 102150, 104291,   1773,\n",
       "           114732,  99918, 102150,  33108,  15946, 101425, 102150, 102008,   1773,\n",
       "           103998, 106012, 115275,   1773,  59258, 105309, 100347,  99285, 100228,\n",
       "            33108,  99888, 113908,   1773, 100004,  73670,   9370, 100205,  33071,\n",
       "           111087, 101037,  11319, 106461,  18830,  46670,  82075,   9370,  87267,\n",
       "            11319, 151643, 151643, 151643, 151643]])}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:53:51.905328Z",
     "start_time": "2024-10-09T08:47:26.987182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=32,\n",
    "    per_device_train_batch_size=17,\n",
    "    per_device_eval_batch_size=17,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ").train()"
   ],
   "id": "22098b4e73b87304",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 06:16, Epoch 32/32]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.663263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.643941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.625116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.606952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.589076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.571695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.554918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.538576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.522751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.507414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.492615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.478424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.464808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.451773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.439322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.427564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.416430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.405935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>13.396133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.386984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.378451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.370603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.363477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.357036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.351311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.346312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.342018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.338453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>13.335600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.754900</td>\n",
       "      <td>13.333467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.754900</td>\n",
       "      <td>13.332042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.754900</td>\n",
       "      <td>13.331331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:53:59.465949Z",
     "start_time": "2024-10-09T08:53:58.830198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save\n",
    "lora_model.save_pretrained(\"./model/qwen2.5-0.5b-disc-med-sft\")"
   ],
   "id": "4e6ddf61f42358b4",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:06:51.982270Z",
     "start_time": "2024-10-09T08:55:35.471798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test\n",
    "model = AutoModelForCausalLM.from_pretrained('./model/qwen2.5-0.5b-disc-med-sft')\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe('足部骨折。你好大夫，谢谢您百忙中的时间。请问骨折对位可以吗？内侧契骨是稍有错位吗？') # 您好，我很高兴能为您提供帮助，根据您的描述，骨折的对位情况还可以。但是，为了更准确地评估情况，我是否可以看一下术前的片子呢？"
   ],
   "id": "c6ad52310e40790b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:  10%|9         | 94.4M/988M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4309d00bf1884a4eb66b3210515d7ef0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fb7b539412848a482842f2b516b7c22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '足部骨折。你好大夫，谢谢您百忙中的时间。请问骨折对位可以吗？内侧契骨是稍有错位吗？谢谢您！\\n根据您的描述，您可能患有足部骨折。骨折对位是指骨折部位与正常位置的关系，如果骨折对位良好，可以恢复到正常位置。如果骨折对位不良，可能需要进行手术治疗。\\n\\n关于内侧契骨的对位情况，需要根据具体的骨折类型和位置来判断。一般来说，如果骨折对位良好，内侧契骨可能不会出现错位。但是，如果骨折对位不良，可能需要进行手术治疗。\\n\\n建议您尽快就医，进行详细的检查和诊断，以便制定合适的治疗方案。'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
